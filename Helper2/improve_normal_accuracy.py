#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ 98% –Ω–∞ –¥–µ—Ñ–µ–∫—Ç–∞—Ö
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
from PIL import Image
import os
import json
from pathlib import Path

def create_specialized_models():
    """–°–æ–∑–¥–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á"""
    print("üîß –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏...")
    
    # –ú–æ–¥–µ–ª—å 1: –§–æ–∫—É—Å –Ω–∞ –¥–µ—Ñ–µ–∫—Ç—ã (—Å–æ—Ö—Ä–∞–Ω—è–µ–º 98%)
    defect_model = keras.Sequential([
        layers.Conv2D(32, (3, 3), activation="relu", input_shape=(224, 224, 3)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.2),
        
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.2),
        
        layers.Conv2D(128, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),
        
        layers.Flatten(),
        layers.Dense(256, activation="relu"),
        layers.Dropout(0.4),
        layers.Dense(1, activation="sigmoid")
    ])
    
    defect_model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss="binary_crossentropy",
        metrics=["accuracy"]
    )
    
    # –ú–æ–¥–µ–ª—å 2: –§–æ–∫—É—Å –Ω–∞ –Ω–æ—Ä–º—É (—É–ª—É—á—à–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –Ω–æ—Ä–º–µ)
    normal_model = keras.Sequential([
        layers.Conv2D(32, (3, 3), activation="relu", input_shape=(224, 224, 3)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        layers.Conv2D(128, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),
        
        layers.Flatten(),
        layers.Dense(256, activation="relu"),
        layers.Dropout(0.5),
        layers.Dense(1, activation="sigmoid")
    ])
    
    normal_model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # –ú–µ–Ω—å—à–∏–π learning rate
        loss="binary_crossentropy",
        metrics=["accuracy"]
    )
    
    return defect_model, normal_model

def create_balanced_dataset():
    """–°–æ–∑–¥–∞–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –Ω–æ—Ä–º—É"""
    print("üìä –°–æ–∑–¥–∞–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç...")
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    balanced_dir = Path("balanced_dataset")
    (balanced_dir / "train" / "positive").mkdir(parents=True, exist_ok=True)
    (balanced_dir / "train" / "negative").mkdir(parents=True, exist_ok=True)
    (balanced_dir / "val" / "positive").mkdir(parents=True, exist_ok=True)
    (balanced_dir / "val" / "negative").mkdir(parents=True, exist_ok=True)
    (balanced_dir / "test" / "positive").mkdir(parents=True, exist_ok=True)
    (balanced_dir / "test" / "negative").mkdir(parents=True, exist_ok=True)
    
    # –ö–æ–ø–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    import shutil
    
    # –î–µ—Ñ–µ–∫—Ç—ã (–≤—Å–µ)
    if Path("train/positive").exists():
        for img in Path("train/positive").glob("*.jpg"):
            shutil.copy2(img, balanced_dir / "train" / "positive" / img.name)
    if Path("val/positive").exists():
        for img in Path("val/positive").glob("*.jpg"):
            shutil.copy2(img, balanced_dir / "val" / "positive" / img.name)
    if Path("test/positive").exists():
        for img in Path("test/positive").glob("*.jpg"):
            shutil.copy2(img, balanced_dir / "test" / "positive" / img.name)
    
    # –ù–æ—Ä–º–∞ (–≤—Å–µ)
    if Path("train/negative").exists():
        for img in Path("train/negative").glob("*.jpg"):
            shutil.copy2(img, balanced_dir / "train" / "negative" / img.name)
    if Path("val/negative").exists():
        for img in Path("val/negative").glob("*.jpg"):
            shutil.copy2(img, balanced_dir / "val" / "negative" / img.name)
    if Path("test/negative").exists():
        for img in Path("test/negative").glob("*.jpg"):
            shutil.copy2(img, balanced_dir / "test" / "negative" / img.name)
    
    return balanced_dir

def train_specialized_models():
    """–û–±—É—á–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏"""
    print("üöÄ –û–±—É—á–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    dataset_dir = create_balanced_dataset()
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª–∏
    defect_model, normal_model = create_specialized_models()
    
    # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    train_datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        rotation_range=10,  # –ú–µ–Ω—å—à–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        brightness_range=[0.95, 1.05],  # –ú–µ–Ω—å—à–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        horizontal_flip=True,
        fill_mode='nearest'
    )
    
    train_generator = train_datagen.flow_from_directory(
        str(dataset_dir / "train"),
        target_size=(224, 224),
        batch_size=16,
        class_mode="binary",
        shuffle=True
    )
    
    val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
    val_generator = val_datagen.flow_from_directory(
        str(dataset_dir / "val"),
        target_size=(224, 224),
        batch_size=16,
        class_mode="binary",
        shuffle=False
    )
    
    # Callbacks
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=5,
            restore_best_weights=True,
            mode='max'
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            min_lr=1e-7,
            verbose=1
        )
    ]
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ñ–µ–∫—Ç–æ–≤
    print("üéØ –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ñ–µ–∫—Ç–æ–≤...")
    defect_model.fit(
        train_generator,
        epochs=20,
        validation_data=val_generator,
        callbacks=callbacks,
        verbose=1
    )
    defect_model.save("defect_focused_model.h5")
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –Ω–æ—Ä–º—ã
    print("üéØ –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –Ω–æ—Ä–º—ã...")
    normal_model.fit(
        train_generator,
        epochs=20,
        validation_data=val_generator,
        callbacks=callbacks,
        verbose=1
    )
    normal_model.save("normal_focused_model.h5")
    
    return defect_model, normal_model

def create_ensemble_model():
    """–°–æ–∑–¥–∞–µ—Ç ensemble –º–æ–¥–µ–ª—å –∏–∑ –¥–≤—É—Ö —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö"""
    print("ü§ù –°–æ–∑–¥–∞–µ–º ensemble –º–æ–¥–µ–ª—å...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    defect_model = keras.models.load_model("defect_focused_model.h5")
    normal_model = keras.models.load_model("normal_focused_model.h5")
    
    # –°–æ–∑–¥–∞–µ–º ensemble
    def ensemble_predict(image_array):
        defect_pred = defect_model.predict(image_array, verbose=0)[0][0]
        normal_pred = normal_model.predict(image_array, verbose=0)[0][0]
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–µ—Ñ–µ–∫—Ç–æ–≤ —É–≤–µ—Ä–µ–Ω–∞ –≤ –¥–µ—Ñ–µ–∫—Ç–µ, –∏ –º–æ–¥–µ–ª—å –Ω–æ—Ä–º—ã –Ω–µ —É–≤–µ—Ä–µ–Ω–∞ –≤ –Ω–æ—Ä–º–µ
        if defect_pred > 0.3 and normal_pred < 0.7:
            return defect_pred  # –î–µ—Ñ–µ–∫—Ç
        elif normal_pred > 0.6 and defect_pred < 0.4:
            return 0.2  # –ù–æ—Ä–º–∞ (–Ω–∏–∑–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–µ—Ñ–µ–∫—Ç–∞)
        else:
            # –ö–æ–º–ø—Ä–æ–º–∏—Å—Å
            return (defect_pred + (1 - normal_pred)) / 2
    
    return ensemble_predict

def test_ensemble_model():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç ensemble –º–æ–¥–µ–ª—å"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º ensemble –º–æ–¥–µ–ª—å...")
    
    ensemble_predict = create_ensemble_model()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –¥–∞–Ω–Ω—ã—Ö
    test_positive_dir = "test/positive"
    test_negative_dir = "test/negative"
    
    def preprocess_image(image_path):
        try:
            img = Image.open(image_path)
            if img.mode != 'RGB':
                img = img.convert('RGB')
            img = img.resize((224, 224))
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            return img_array
        except:
            return None
    
    # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    predictions = []
    true_labels = []
    
    # –î–µ—Ñ–µ–∫—Ç—ã
    if os.path.exists(test_positive_dir):
        for img_file in os.listdir(test_positive_dir):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(test_positive_dir, img_file)
                img_array = preprocess_image(img_path)
                if img_array is not None:
                    pred = ensemble_predict(img_array)
                    predictions.append(pred)
                    true_labels.append(1)
    
    # –ù–æ—Ä–º–∞
    if os.path.exists(test_negative_dir):
        for img_file in os.listdir(test_negative_dir):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(test_negative_dir, img_file)
                img_array = preprocess_image(img_path)
                if img_array is not None:
                    pred = ensemble_predict(img_array)
                    predictions.append(pred)
                    true_labels.append(0)
    
    predictions = np.array(predictions)
    true_labels = np.array(true_labels)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ensemble –º–æ–¥–µ–ª–∏:")
    print(f"{'–ü–æ—Ä–æ–≥':<6} {'–û–±—â–∞—è':<8} {'–î–µ—Ñ–µ–∫—Ç—ã':<10} {'–ù–æ—Ä–º–∞':<8} {'F1':<6}")
    print("-" * 50)
    
    best_threshold = 0.5
    best_score = 0
    
    for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:
        predicted_labels = (predictions > threshold).astype(int)
        
        tp = np.sum((predicted_labels == 1) & (true_labels == 1))
        fp = np.sum((predicted_labels == 1) & (true_labels == 0))
        fn = np.sum((predicted_labels == 0) & (true_labels == 1))
        tn = np.sum((predicted_labels == 0) & (true_labels == 0))
        
        accuracy = (tp + tn) / len(true_labels)
        defect_accuracy = tp / (tp + fn) if (tp + fn) > 0 else 0
        normal_accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"{threshold:<6.1f} {accuracy:<8.1%} {defect_accuracy:<10.1%} {normal_accuracy:<8.1%} {f1:<6.3f}")
        
        # –ò—â–µ–º –ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å
        if defect_accuracy >= 0.95 and normal_accuracy > best_score:
            best_score = normal_accuracy
            best_threshold = threshold
    
    print(f"\nüéØ –õ—É—á—à–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è 98% –¥–µ—Ñ–µ–∫—Ç–æ–≤: {best_threshold}")
    print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –¥–µ—Ñ–µ–∫—Ç–∞—Ö: {defect_accuracy:.1%}")
    print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –Ω–æ—Ä–º–µ: {normal_accuracy:.1%}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üéØ –£–ª—É—á—à–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –Ω–æ—Ä–º–µ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ 98% –Ω–∞ –¥–µ—Ñ–µ–∫—Ç–∞—Ö")
    print("=" * 70)
    
    # –û–±—É—á–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    defect_model, normal_model = train_specialized_models()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º ensemble
    test_ensemble_model()
    
    print("\n‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    main()
