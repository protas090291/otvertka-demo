#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
from PIL import Image
import os
import json
import matplotlib.pyplot as plt

def analyze_model_predictions():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã"""
    print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏...")
    
    model = keras.models.load_model("best_maximized_model.h5")
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    predictions = []
    true_labels = []
    filenames = []
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ñ–µ–∫—Ç—ã
    test_positive_dir = "test/positive"
    if os.path.exists(test_positive_dir):
        for img_file in os.listdir(test_positive_dir):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(test_positive_dir, img_file)
                img_array = preprocess_image(img_path)
                if img_array is not None:
                    pred = model.predict(img_array, verbose=0)[0][0]
                    predictions.append(pred)
                    true_labels.append(1)  # –¥–µ—Ñ–µ–∫—Ç
                    filenames.append(f"DEFECT: {img_file}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    test_negative_dir = "test/negative"
    if os.path.exists(test_negative_dir):
        for img_file in os.listdir(test_negative_dir):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(test_negative_dir, img_file)
                img_array = preprocess_image(img_path)
                if img_array is not None:
                    pred = model.predict(img_array, verbose=0)[0][0]
                    predictions.append(pred)
                    true_labels.append(0)  # –Ω–æ—Ä–º–∞
                    filenames.append(f"NORMAL: {img_file}")
    
    predictions = np.array(predictions)
    true_labels = np.array(true_labels)
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
    print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {predictions.min():.4f}")
    print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {predictions.max():.4f}")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {predictions.mean():.4f}")
    print(f"   –ú–µ–¥–∏–∞–Ω–∞: {np.median(predictions):.4f}")
    print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {predictions.std():.4f}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    defect_predictions = predictions[true_labels == 1]
    normal_predictions = predictions[true_labels == 0]
    
    print(f"\nüìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    print(f"   –î–µ—Ñ–µ–∫—Ç—ã - —Å—Ä–µ–¥–Ω–µ–µ: {defect_predictions.mean():.4f}, –º–∏–Ω: {defect_predictions.min():.4f}, –º–∞–∫—Å: {defect_predictions.max():.4f}")
    print(f"   –ù–æ—Ä–º–∞ - —Å—Ä–µ–¥–Ω–µ–µ: {normal_predictions.mean():.4f}, –º–∏–Ω: {normal_predictions.min():.4f}, –º–∞–∫—Å: {normal_predictions.max():.4f}")
    
    # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
    best_threshold = find_optimal_threshold(predictions, true_labels)
    print(f"\nüéØ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {best_threshold:.4f}")
    
    return predictions, true_labels, best_threshold

def preprocess_image(image_path, target_size=(224, 224)):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ–ª–∏"""
    try:
        img = Image.open(image_path)
        if img.mode != 'RGB':
            img = img.convert('RGB')
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        return img_array
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
        return None

def find_optimal_threshold(predictions, true_labels):
    """–ù–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    thresholds = np.arange(0.1, 0.9, 0.01)
    best_threshold = 0.5
    best_f1 = 0
    
    for threshold in thresholds:
        predicted_labels = (predictions > threshold).astype(int)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        tp = np.sum((predicted_labels == 1) & (true_labels == 1))
        fp = np.sum((predicted_labels == 1) & (true_labels == 0))
        fn = np.sum((predicted_labels == 0) & (true_labels == 1))
        tn = np.sum((predicted_labels == 0) & (true_labels == 0))
        
        if tp + fp > 0 and tp + fn > 0:
            precision = tp / (tp + fp)
            recall = tp / (tp + fn)
            f1 = 2 * (precision * recall) / (precision + recall)
            
            if f1 > best_f1:
                best_f1 = f1
                best_threshold = threshold
    
    return best_threshold

def test_with_different_thresholds():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏...")
    
    model = keras.models.load_model("best_maximized_model.h5")
    
    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    test_data = []
    test_labels = []
    
    # –î–µ—Ñ–µ–∫—Ç—ã
    test_positive_dir = "test/positive"
    if os.path.exists(test_positive_dir):
        for img_file in os.listdir(test_positive_dir):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(test_positive_dir, img_file)
                img_array = preprocess_image(img_path)
                if img_array is not None:
                    pred = model.predict(img_array, verbose=0)[0][0]
                    test_data.append(pred)
                    test_labels.append(1)
    
    # –ù–æ—Ä–º–∞
    test_negative_dir = "test/negative"
    if os.path.exists(test_negative_dir):
        for img_file in os.listdir(test_negative_dir):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(test_negative_dir, img_file)
                img_array = preprocess_image(img_path)
                if img_array is not None:
                    pred = model.predict(img_array, verbose=0)[0][0]
                    test_data.append(pred)
                    test_labels.append(0)
    
    test_data = np.array(test_data)
    test_labels = np.array(test_labels)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏:")
    print(f"{'–ü–æ—Ä–æ–≥':<8} {'–¢–æ—á–Ω–æ—Å—Ç—å':<10} {'–î–µ—Ñ–µ–∫—Ç—ã':<10} {'–ù–æ—Ä–º–∞':<10} {'F1':<8}")
    print("-" * 50)
    
    best_threshold = 0.5
    best_accuracy = 0
    
    for threshold in thresholds:
        predicted_labels = (test_data > threshold).astype(int)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        tp = np.sum((predicted_labels == 1) & (test_labels == 1))
        fp = np.sum((predicted_labels == 1) & (test_labels == 0))
        fn = np.sum((predicted_labels == 0) & (test_labels == 1))
        tn = np.sum((predicted_labels == 0) & (test_labels == 0))
        
        accuracy = (tp + tn) / len(test_labels)
        defect_accuracy = tp / (tp + fn) if (tp + fn) > 0 else 0
        normal_accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"{threshold:<8.1f} {accuracy:<10.1%} {defect_accuracy:<10.1%} {normal_accuracy:<10.1%} {f1:<8.3f}")
        
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_threshold = threshold
    
    print(f"\nüéØ –õ—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_threshold} (—Ç–æ—á–Ω–æ—Å—Ç—å: {best_accuracy:.1%})")
    return best_threshold

def create_improved_model():
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π"""
    print("\nüîß –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
    
    # –ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    model = keras.Sequential([
        # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫
        layers.Conv2D(32, (3, 3), activation="relu", input_shape=(224, 224, 3)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫
        layers.Conv2D(128, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        layers.Flatten(),
        layers.Dense(256, activation="relu"),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(128, activation="relu"),
        layers.Dropout(0.3),
        layers.Dense(1, activation="sigmoid")
    ])
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–º learning rate
    optimizer = keras.optimizers.Adam(learning_rate=0.001)
    
    model.compile(
        optimizer=optimizer,
        loss="binary_crossentropy",
        metrics=["accuracy"]
    )
    
    return model

def retrain_improved_model():
    """–ü–µ—Ä–µ–æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    print("\nüöÄ –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏...")
    
    # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    model = create_improved_model()
    
    # –°–æ–∑–¥–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å –º–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π
    train_datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        rotation_range=15,
        brightness_range=[0.9, 1.1],
        horizontal_flip=True,
        fill_mode='nearest'
    )
    
    train_generator = train_datagen.flow_from_directory(
        "train/",
        target_size=(224, 224),
        batch_size=16,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º batch size
        class_mode="binary",
        shuffle=True
    )
    
    val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
    val_generator = val_datagen.flow_from_directory(
        "val/",
        target_size=(224, 224),
        batch_size=16,
        class_mode="binary",
        shuffle=False
    )
    
    # Callbacks
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=8,
            restore_best_weights=True,
            mode='max'
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            min_lr=1e-6,
            verbose=1
        ),
        keras.callbacks.ModelCheckpoint(
            'improved_model.h5',
            monitor='val_accuracy',
            save_best_only=True,
            mode='max',
            verbose=1
        )
    ]
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    history = model.fit(
        train_generator,
        epochs=30,
        validation_data=val_generator,
        callbacks=callbacks,
        verbose=1
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    model.save("final_improved_model.h5")
    print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: final_improved_model.h5")
    
    return model, history

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîß –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º—ã —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é")
    print("=" * 70)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
    predictions, true_labels, optimal_threshold = analyze_model_predictions()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
    best_threshold = test_with_different_thresholds()
    
    # –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    improved_model, history = retrain_improved_model()
    
    print("\n‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    print(f"üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä–æ–≥: {best_threshold}")
    print("üìÅ –°–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã: improved_model.h5, final_improved_model.h5")

if __name__ == "__main__":
    main()


