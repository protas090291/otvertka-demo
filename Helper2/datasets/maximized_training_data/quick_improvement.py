#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –Ω–æ—Ä–º–µ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ 98% –Ω–∞ –¥–µ—Ñ–µ–∫—Ç–∞—Ö
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
from PIL import Image
import os

def create_optimized_model():
    """–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º –±–∞–ª–∞–Ω—Å–æ–º"""
    print("üîß –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
    
    # –ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –ª—É—á—à–∏–º –±–∞–ª–∞–Ω—Å–æ–º
    model = keras.Sequential([
        # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫
        layers.Conv2D(32, (3, 3), activation="relu", input_shape=(224, 224, 3)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.2),
        
        # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.2),
        
        # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫
        layers.Conv2D(128, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        layers.Flatten(),
        layers.Dense(256, activation="relu"),
        layers.BatchNormalization(),
        layers.Dropout(0.4),
        layers.Dense(128, activation="relu"),
        layers.Dropout(0.3),
        layers.Dense(1, activation="sigmoid")
    ])
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å –º–µ–Ω—å—à–∏–º learning rate –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    optimizer = keras.optimizers.Adam(learning_rate=0.0005)
    
    model.compile(
        optimizer=optimizer,
        loss="binary_crossentropy",
        metrics=["accuracy"]
    )
    
    return model

def train_optimized_model():
    """–û–±—É—á–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    print("üöÄ –û–±—É—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
    
    model = create_optimized_model()
    
    # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–π –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π
    train_datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        rotation_range=10,  # –ú–µ–Ω—å—à–µ –ø–æ–≤–æ—Ä–æ—Ç–æ–≤
        brightness_range=[0.95, 1.05],  # –ú–µ–Ω—å—à–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π —è—Ä–∫–æ—Å—Ç–∏
        horizontal_flip=True,
        fill_mode='nearest'
    )
    
    train_generator = train_datagen.flow_from_directory(
        "train/",
        target_size=(224, 224),
        batch_size=16,
        class_mode="binary",
        shuffle=True
    )
    
    val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
    val_generator = val_datagen.flow_from_directory(
        "val/",
        target_size=(224, 224),
        batch_size=16,
        class_mode="binary",
        shuffle=False
    )
    
    # Callbacks —Å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º early stopping
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=3,  # –ú–µ–Ω—å—à–µ patience
            restore_best_weights=True,
            mode='max'
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.3,  # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ
            patience=2,
            min_lr=1e-6,
            verbose=1
        ),
        keras.callbacks.ModelCheckpoint(
            'optimized_model.h5',
            monitor='val_accuracy',
            save_best_only=True,
            mode='max',
            verbose=1
        )
    ]
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    history = model.fit(
        train_generator,
        epochs=15,  # –ú–µ–Ω—å—à–µ —ç–ø–æ—Ö
        validation_data=val_generator,
        callbacks=callbacks,
        verbose=1
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    model.save("final_optimized_model.h5")
    print("‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: final_optimized_model.h5")
    
    return model

def test_optimized_model():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
    
    try:
        model = keras.models.load_model("optimized_model.h5")
        print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å –∏–∑ –æ–±—É—á–µ–Ω–∏—è")
    except:
        try:
            model = keras.models.load_model("final_optimized_model.h5")
            print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å")
        except:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
            return
    
    def preprocess_image(image_path):
        try:
            img = Image.open(image_path)
            if img.mode != 'RGB':
                img = img.convert('RGB')
            img = img.resize((224, 224))
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            return img_array
        except:
            return None
    
    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    test_data = []
    test_labels = []
    
    # –î–µ—Ñ–µ–∫—Ç—ã
    test_positive_dir = "test/positive"
    if os.path.exists(test_positive_dir):
        for img_file in os.listdir(test_positive_dir):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(test_positive_dir, img_file)
                img_array = preprocess_image(img_path)
                if img_array is not None:
                    pred = model.predict(img_array, verbose=0)[0][0]
                    test_data.append(pred)
                    test_labels.append(1)
    
    # –ù–æ—Ä–º–∞
    test_negative_dir = "test/negative"
    if os.path.exists(test_negative_dir):
        for img_file in os.listdir(test_negative_dir):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(test_negative_dir, img_file)
                img_array = preprocess_image(img_path)
                if img_array is not None:
                    pred = model.predict(img_array, verbose=0)[0][0]
                    test_data.append(pred)
                    test_labels.append(0)
    
    test_data = np.array(test_data)
    test_labels = np.array(test_labels)
    
    print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(test_data)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:")
    print(f"{'–ü–æ—Ä–æ–≥':<6} {'–û–±—â–∞—è':<8} {'–î–µ—Ñ–µ–∫—Ç—ã':<10} {'–ù–æ—Ä–º–∞':<8} {'F1':<6} {'–û—Ü–µ–Ω–∫–∞':<15}")
    print("-" * 70)
    
    best_threshold = 0.5
    best_score = 0
    
    for threshold in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:
        predicted_labels = (test_data > threshold).astype(int)
        
        tp = np.sum((predicted_labels == 1) & (test_labels == 1))
        fp = np.sum((predicted_labels == 1) & (test_labels == 0))
        fn = np.sum((predicted_labels == 0) & (test_labels == 1))
        tn = np.sum((predicted_labels == 0) & (test_labels == 0))
        
        accuracy = (tp + tn) / len(test_labels)
        defect_accuracy = tp / (tp + fn) if (tp + fn) > 0 else 0
        normal_accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        # –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if defect_accuracy >= 0.95 and normal_accuracy >= 0.5:
            evaluation = "üèÜ –û–¢–õ–ò–ß–ù–û"
        elif defect_accuracy >= 0.9 and normal_accuracy >= 0.3:
            evaluation = "‚úÖ –•–û–†–û–®–û"
        elif defect_accuracy >= 0.8:
            evaluation = "‚ö†Ô∏è –£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û"
        else:
            evaluation = "‚ùå –ü–õ–û–•–û"
        
        print(f"{threshold:<6.1f} {accuracy:<8.1%} {defect_accuracy:<10.1%} {normal_accuracy:<8.1%} {f1:<6.3f} {evaluation:<15}")
        
        # –ò—â–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º 98% –Ω–∞ –¥–µ—Ñ–µ–∫—Ç–∞—Ö
        if defect_accuracy >= 0.95 and normal_accuracy > best_score:
            best_score = normal_accuracy
            best_threshold = threshold
    
    print(f"\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:")
    if best_score > 0:
        print(f"‚úÖ –õ—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_threshold}")
        print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –¥–µ—Ñ–µ–∫—Ç–∞—Ö: {defect_accuracy:.1%}")
        print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –Ω–æ—Ä–º–µ: {normal_accuracy:.1%}")
        print(f"   –≠—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏!")
    else:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ—Ä–æ–≥ —Å 95%+ –Ω–∞ –¥–µ—Ñ–µ–∫—Ç–∞—Ö –∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –Ω–æ—Ä–º–µ")
        print(f"   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Ä–æ–≥ 0.3 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üéØ –ë—ã—Å—Ç—Ä–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –Ω–æ—Ä–º–µ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ 98% –Ω–∞ –¥–µ—Ñ–µ–∫—Ç–∞—Ö")
    print("=" * 70)
    
    # –û–±—É—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    model = train_optimized_model()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º
    test_optimized_model()
    
    print("\n‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    main()


