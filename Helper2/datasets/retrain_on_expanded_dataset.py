#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
"""

import os
import shutil
from pathlib import Path
import json

def prepare_expanded_dataset():
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    print("üîÑ –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç...")
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    train_dir = Path("expanded_training_data")
    train_dir.mkdir(exist_ok=True)
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    (train_dir / "train" / "positive").mkdir(parents=True, exist_ok=True)
    (train_dir / "train" / "negative").mkdir(parents=True, exist_ok=True)
    (train_dir / "val" / "positive").mkdir(parents=True, exist_ok=True)
    (train_dir / "val" / "negative").mkdir(parents=True, exist_ok=True)
    (train_dir / "test" / "positive").mkdir(parents=True, exist_ok=True)
    (train_dir / "test" / "negative").mkdir(parents=True, exist_ok=True)
    
    # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ expanded_dataset
    source_positive = Path("expanded_dataset/positive")
    source_negative = Path("expanded_dataset/negative")
    
    if source_positive.exists():
        positive_images = list(source_positive.glob("*.jpg"))
        negative_images = list(source_negative.glob("*.jpg"))
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
        print(f"   –î–µ—Ñ–µ–∫—Ç—ã: {len(positive_images)}")
        print(f"   –ù–æ—Ä–º–∞: {len(negative_images)}")
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val/test (70%/15%/15%)
        train_pos = positive_images[:int(len(positive_images) * 0.7)]
        val_pos = positive_images[int(len(positive_images) * 0.7):int(len(positive_images) * 0.85)]
        test_pos = positive_images[int(len(positive_images) * 0.85):]
        
        train_neg = negative_images[:int(len(negative_images) * 0.7)]
        val_neg = negative_images[int(len(negative_images) * 0.7):int(len(negative_images) * 0.85)]
        test_neg = negative_images[int(len(negative_images) * 0.85):]
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
        for img in train_pos:
            shutil.copy2(img, train_dir / "train" / "positive" / img.name)
        for img in val_pos:
            shutil.copy2(img, train_dir / "val" / "positive" / img.name)
        for img in test_pos:
            shutil.copy2(img, train_dir / "test" / "positive" / img.name)
            
        for img in train_neg:
            shutil.copy2(img, train_dir / "train" / "negative" / img.name)
        for img in val_neg:
            shutil.copy2(img, train_dir / "val" / "negative" / img.name)
        for img in test_neg:
            shutil.copy2(img, train_dir / "test" / "negative" / img.name)
        
        print(f"‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:")
        print(f"   Train: {len(train_pos)} –¥–µ—Ñ–µ–∫—Ç–æ–≤, {len(train_neg)} –Ω–æ—Ä–º–∞")
        print(f"   Val: {len(val_pos)} –¥–µ—Ñ–µ–∫—Ç–æ–≤, {len(val_neg)} –Ω–æ—Ä–º–∞")
        print(f"   Test: {len(test_pos)} –¥–µ—Ñ–µ–∫—Ç–æ–≤, {len(test_neg)} –Ω–æ—Ä–º–∞")
    
    return train_dir

def create_expanded_config():
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    config = {
        "dataset_name": "expanded_concrete_defects",
        "description": "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–µ—Ñ–µ–∫—Ç–æ–≤ –±–µ—Ç–æ–Ω–∞ —Å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏",
        "classes": {
            "positive": "–î–µ—Ñ–µ–∫—Ç—ã (—Ç—Ä–µ—â–∏–Ω—ã, –ø—è—Ç–Ω–∞, –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è)",
            "negative": "–ù–æ—Ä–º–∞–ª—å–Ω—ã–π –±–µ—Ç–æ–Ω –±–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤"
        },
        "image_size": [224, 224],
        "augmentation": {
            "rotation": 20,
            "brightness": 0.3,
            "contrast": 0.3,
            "horizontal_flip": True,
            "zoom_range": 0.2
        },
        "training": {
            "batch_size": 16,
            "epochs": 20,
            "learning_rate": 0.0005,
            "validation_split": 0.2
        }
    }
    
    return config

def create_retrain_script():
    """–°–æ–∑–¥–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
    script_content = '''#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import json
from pathlib import Path
import numpy as np

def load_dataset_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    with open("expanded_dataset_config.json", "r", encoding="utf-8") as f:
        return json.load(f)

def create_data_generators(config):
    """–°–æ–∑–¥–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    train_datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        rotation_range=config["augmentation"]["rotation"],
        brightness_range=[1-config["augmentation"]["brightness"], 
                         1+config["augmentation"]["brightness"]],
        horizontal_flip=config["augmentation"]["horizontal_flip"],
        zoom_range=config["augmentation"]["zoom_range"]
    )
    
    train_generator = train_datagen.flow_from_directory(
        "train/",
        target_size=tuple(config["image_size"]),
        batch_size=config["training"]["batch_size"],
        class_mode="binary"
    )
    
    val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
    val_generator = val_datagen.flow_from_directory(
        "val/",
        target_size=tuple(config["image_size"]),
        batch_size=config["training"]["batch_size"],
        class_mode="binary"
    )
    
    return train_generator, val_generator

def create_improved_model(config):
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    model = keras.Sequential([
        layers.Conv2D(32, (3, 3), activation="relu", input_shape=(*config["image_size"], 3)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        layers.Conv2D(128, (3, 3), activation="relu"),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        layers.Flatten(),
        layers.Dense(512, activation="relu"),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(256, activation="relu"),
        layers.Dropout(0.5),
        layers.Dense(1, activation="sigmoid")
    ])
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=config["training"]["learning_rate"]),
        loss="binary_crossentropy",
        metrics=["accuracy", "precision", "recall"]
    )
    
    return model

def train_expanded_model():
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ"""
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = load_dataset_config()
    
    # –°–æ–∑–¥–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    train_gen, val_gen = create_data_generators(config)
    
    # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    model = create_improved_model(config)
    
    # –í—ã–≤–æ–¥–∏–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏
    model.summary()
    
    # Callbacks –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            min_lr=1e-7
        )
    ]
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    history = model.fit(
        train_gen,
        epochs=config["training"]["epochs"],
        validation_data=val_gen,
        callbacks=callbacks,
        verbose=1
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model.save("expanded_concrete_defect_model.h5")
    print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: expanded_concrete_defect_model.h5")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
    with open("training_history.json", "w") as f:
        json.dump({
            'loss': [float(x) for x in history.history['loss']],
            'accuracy': [float(x) for x in history.history['accuracy']],
            'val_loss': [float(x) for x in history.history['val_loss']],
            'val_accuracy': [float(x) for x in history.history['val_accuracy']]
        }, f)
    
    return model, history

if __name__ == "__main__":
    train_expanded_model()
'''
    
    return script_content

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ")
    print("=" * 70)
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    train_dir = prepare_expanded_dataset()
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = create_expanded_config()
    with open(train_dir / "expanded_dataset_config.json", "w", encoding="utf-8") as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    # –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    script_content = create_retrain_script()
    with open(train_dir / "retrain_model.py", "w", encoding="utf-8") as f:
        f.write(script_content)
    
    print(f"\n‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {train_dir}")
    print(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {train_dir}/expanded_dataset_config.json")
    print(f"ü§ñ –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è: {train_dir}/retrain_model.py")
    
    print(f"\nüéØ –î–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è:")
    print(f"   cd {train_dir}")
    print(f"   python retrain_model.py")

if __name__ == "__main__":
    main()


