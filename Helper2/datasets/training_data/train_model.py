#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–µ—Ñ–µ–∫—Ç–æ–≤ –±–µ—Ç–æ–Ω–∞
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import json
from pathlib import Path
import numpy as np

def load_dataset_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    with open("dataset_config.json", "r", encoding="utf-8") as f:
        return json.load(f)

def create_data_generators(config):
    """–°–æ–∑–¥–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    train_datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        rotation_range=config["augmentation"]["rotation"],
        brightness_range=[1-config["augmentation"]["brightness"], 
                         1+config["augmentation"]["brightness"]],
        horizontal_flip=config["augmentation"]["horizontal_flip"]
    )
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å –º–∞–ª–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    train_generator = train_datagen.flow_from_directory(
        "train/",
        target_size=tuple(config["image_size"]),
        batch_size=min(config["training"]["batch_size"], 4),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º batch_size
        class_mode="binary"
    )
    
    # –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–∑ test –¥–∞–Ω–Ω—ã—Ö
    val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
    val_generator = val_datagen.flow_from_directory(
        "test/",
        target_size=tuple(config["image_size"]),
        batch_size=1,  # –ú–∞–ª–µ–Ω—å–∫–∏–π batch –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        class_mode="binary"
    )
    
    return train_generator, val_generator

def create_model(config):
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    model = keras.Sequential([
        layers.Conv2D(32, (3, 3), activation="relu", input_shape=(*config["image_size"], 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.Flatten(),
        layers.Dense(64, activation="relu"),
        layers.Dropout(0.5),
        layers.Dense(1, activation="sigmoid")
    ])
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=config["training"]["learning_rate"]),
        loss="binary_crossentropy",
        metrics=["accuracy"]
    )
    
    return model

def train_model():
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å"""
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = load_dataset_config()
    
    # –°–æ–∑–¥–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    train_gen, val_gen = create_data_generators(config)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = create_model(config)
    
    # –í—ã–≤–æ–¥–∏–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏
    model.summary()
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    history = model.fit(
        train_gen,
        epochs=config["training"]["epochs"],
        validation_data=val_gen,
        verbose=1
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model.save("concrete_defect_model.h5")
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: concrete_defect_model.h5")
    
    return model, history

if __name__ == "__main__":
    train_model()
